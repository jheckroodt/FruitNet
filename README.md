# Object Detection from Scratch

# Short Description
Without the aid of any deep learning framework, this 12-layer convolutional neural network is designed to detect and classify a single object in a 128 by 128 color image into any one of six classes of fruit.

# Extended Description
This convoluional neural network has 12 layers: 2 convolutional layers, followed by a single max pooling layer, followed by a further 6 convolutional layers, and concluded by a single fully connected layer. The aim of the network is to receive, as input, a 128 by 128 color (RGB) image, and subsequently detect and classify a single object in the given image as belonging to any one of six classes of fruit (the possibility of none of the six possible fruits being present does not exist in the case of this network, which is a consequence of the training set). The network does so by using a linear activation function (in the final layer), and a particular loss function (expressed in full in `training_notebook.ipynb` in the relative branch). Lastly, as is mentioned in the short description, too, the key feature of this particular network, is that it has been implemented without the aid of any deep learning framework. The only libraries we have used in this particular implementation is `Pandas`, `h5py`, and, finally, `NumPy` (and, technically `matplotlib`, although this library is not necessary for the actual training of our network, but rather only for aesthetic value).

# File Descriptions

`training_schedule.txt`: Of course, given that linear regression is not the optimal approach to abide by when designing a classification network, it is necessary to devise a training schedule for this network, so that we may pre-train the relevant layers to specialize in classification, and fine tune an additional pair of layers to specialize in detection. For this reason, we've included the entire training schedule in `training_schedule.txt`.

`pretraining_hparams.txt`/`tuning_hparams.txt`: Given that we are both pre-training and fine tuning our network, we encounter the need for two different sets of hyperparameters (one for the pre-training stage of training, and another for the fine tuning stage of training). For this reason, we've included the hyperparameters for the pre-training stage, and the hyperparameters for the fine tuning stage in `pretraining_hparams.txt` and `tuning_hparams.txt`, respectively. Although these hyperparameters are stored in `.md` files, they are written in Python dictionary format.

`training_set.h5`: Of course, to start training any neural network, we require a labelled dataset. Our dataset consists of 600 color images of resolution 128 by 128. The images themselves contain exactly one of the following six fruits: an apple, bananas, grapes, a kiwi, a lemon, or an orange (it is because of the fact that our training set images contain exactly one fruit that we have not accounted for the possibility of there being no fruit in the given image). The given fruit are presented on a plain white background, for easily detectability. The particular dataset in this file in which our images are stored is titled `training_set_inputs`. Next, it is of course necessary to address the nature of our image labels. Each of our images correspond to a single 10-dimensional column vector (called the image's label). The first 6 elements of the image's label contain the probabilities that the object detected in the image belongs to the apple class, bananas class, grapes class, kiwis class, lemons class, or oranges class, respectively. Finally, the remaining 4 elements of the image's label contain the encoding for the bounding box. That is, the sevent, eighth, ninth, and tenth element of the image's label contain the x-ordinate of the top left corner of the bounding box, the y-ordinate of the top left corner of the bounding box, the width of the bounding box, and the height of the bounding box. All four of these final elements are measured in pixels. The name of the dataset in our `.h5` file responsible for storing the given collection of labels is given by `training_set_labels`. Lastly, it should be noted that each of the elements of every image's labels is normalized to fall between 0 and 1, whereas the pixel intensities of each of the images themselves, are not.

`dataset_funcs.py`: This Python script contains three methods:
- `build_dataset`, which is responsible for reading the relevant datasets from our `training_set.h5` file, and subsequently storing them in the appropriate Python variables
